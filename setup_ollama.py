"""
Script para setup e teste do Ollama/LLaMA
"""
import subprocess
import sys
import os

def install_ollama():
    """Instala Ollama se n√£o estiver presente."""
    print("üì• Instalando depend√™ncia ollama...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "ollama"])
    print("‚úì Ollama instalado")

def check_ollama_server():
    """Verifica se servidor Ollama est√° rodando."""
    try:
        import ollama
        print("üîç Verificando servidor Ollama...")
        
        try:
            response = ollama.list(host="http://localhost:11434")
            print("‚úì Servidor Ollama respondendo!")
            return True
        except Exception as e:
            print(f"‚ùå Servidor Ollama n√£o respondendo: {e}")
            print("\nüìã Para iniciar Ollama, abra um terminal e execute:")
            print("   ollama serve")
            return False
            
    except ImportError:
        print("‚ö†Ô∏è  Biblioteca ollama n√£o instalada")
        return False

def pull_llama_model():
    """Baixa modelo LLaMA se n√£o estiver presente."""
    try:
        import ollama
        print("\nüì• Verificando modelo LLaMA...")
        
        try:
            response = ollama.list(host="http://localhost:11434")
            models = [m.get('name') for m in response.get('models', [])]
            
            if 'llama2:latest' in models or any('llama2' in m for m in models):
                print("‚úì LLaMA 2 j√° est√° instalado")
                return True
            else:
                print("‚¨áÔ∏è  Baixando LLaMA 2 (pode demorar alguns minutos)...")
                print("   Tamanho: ~3.8 GB")
                
                response = ollama.pull("llama2", host="http://localhost:11434")
                print("‚úì LLaMA 2 baixado com sucesso!")
                return True
                
        except Exception as e:
            print(f"‚ùå Erro ao gerenciar modelos: {e}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return False

def test_llama():
    """Testa gera√ß√£o de texto com LLaMA."""
    try:
        import ollama
        print("\nüß™ Testando LLaMA...")
        
        response = ollama.generate(
            model="llama2",
            prompt="Responda com uma s√≥ palavra: OK",
            host="http://localhost:11434"
        )
        
        result = response.get('response', '').strip()
        print(f"‚úì Resposta LLaMA: {result}")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")
        return False

def main():
    print("="*60)
    print(" SETUP OLLAMA/LLAMA2")
    print("="*60)
    
    # Passo 1: Instalar ollama
    try:
        import ollama
        print("‚úì Biblioteca ollama j√° instalada")
    except ImportError:
        install_ollama()
    
    # Passo 2: Verificar servidor
    print()
    if not check_ollama_server():
        print("\n‚ö†Ô∏è  Inicie o servidor Ollama antes de continuar")
        return False
    
    # Passo 3: Baixar modelo
    print()
    if not pull_llama_model():
        print("\n‚ö†Ô∏è  Erro ao baixar modelo")
        return False
    
    # Passo 4: Testar
    print()
    if not test_llama():
        print("\n‚ö†Ô∏è  Erro no teste de gera√ß√£o")
        return False
    
    print("\n" + "="*60)
    print("‚úÖ SETUP COMPLETO!")
    print("="*60)
    print("\nüìù Para usar Ollama no pipeline:")
    print("   1. Edite .env e altere: OLLAMA_ENABLED=true")
    print("   2. Execute: python main.py")
    print("\nüí° Para manter Ollama rodando em background:")
    print("   - Linux/Mac: ollama serve &")
    print("   - Windows: Abra novo terminal com 'ollama serve'")
    
    return True

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
